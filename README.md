# ğŸ“š Book Recommendation System

A personalised book recommendation web app built with Python and Streamlit, developed as an individual project after completing the NLP course.

The system analyses book reviews using Natural Language Processing (NLP) to recommend books based on a user's preferred genre and keywords. It combines sentiment analysis and topic modelling to rank and surface the most relevant books.

---

## ğŸ§  How It Works

1. User selects a **genre** and enters a **keyword** (e.g. `adventure`, `inspiring`, `dark`)
2. The app searches book reviews for fuzzy keyword matches
3. Matched books are scored using **VADER sentiment analysis** + **star rating**
4. Top 10 books are ranked and returned
5. **LDA topic modelling** extracts key themes from those reviews

---

## ğŸ—‚ï¸ Project Structure

```
BookRecommendationSystem/
â”‚
â”œâ”€â”€ app.py                    # Streamlit web app
â”œâ”€â”€ analysis_summary.py       # Core recommendation engine
â”œâ”€â”€ sentiment_analysis.py     # VADER sentiment scoring
â”œâ”€â”€ topic_modeling.py         # LDA topic modelling
â”œâ”€â”€ Genre_filter.py           # Splits master CSV into genre CSVs
â”œâ”€â”€ test_recommendations.py   # Pytest test suite
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ books_and_reviews.csv         # Master dataset (not included)
â”‚   â”œâ”€â”€ Books_rating.csv              # Ratings dataset (not included)
â”‚   â”œâ”€â”€ New_google_api_dataset.csv    # Google Books data (not included)
â”‚   â””â”€â”€ filtered_reviews/            # Auto-generated by Genre_filter.py
â”‚       â”œâ”€â”€ fiction_df.csv
â”‚       â”œâ”€â”€ history_df.csv
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ notebooks/
    â”œâ”€â”€ Exploratory_Analysis_Books_Reviews.ipynb
    â”œâ”€â”€ Exploratory_Analysis_Google_Data.ipynb
    â”œâ”€â”€ sentiment_analysis.ipynb
    â”œâ”€â”€ tf-idf.ipynb
    â”œâ”€â”€ topic_modelling.ipynb
    â””â”€â”€ Visual_Analysis.ipynb
```

---

## âš™ï¸ Installation

```bash
pip install streamlit pandas nltk scikit-learn fuzzywuzzy python-Levenshtein wordcloud matplotlib seaborn pytest
```

Download required NLTK data (one-time):
```bash
python3 -c "import nltk; nltk.download('vader_lexicon'); nltk.download('stopwords'); nltk.download('punkt'); nltk.download('punkt_tab')"
```

---

## ğŸš€ Usage

### Step 1 â€” Add your data
Place your CSV files inside the `Data/` folder. The master dataset is not included in this repo due to file size.

### Step 2 â€” Generate genre CSVs
```bash
python Genre_filter.py
```
This creates one CSV per genre inside `Data/filtered_reviews/`. Only needs to be run once.

### Step 3 â€” Run the app
```bash
streamlit run app.py
```
Opens at `http://localhost:8501`

### Step 4 â€” Run tests
```bash
pytest test_recommendations.py -v
```

---

## ğŸ§ª Test Results

```
test_normal_input        PASSED
test_no_matching_books   PASSED
test_all_books_match     PASSED
test_case                PASSED
test_invalid_input       PASSED

5 passed in 31s
```

---

## ğŸ› ï¸ Tech Stack

| Library | Use |
|---|---|
| `streamlit` | Web interface |
| `nltk (VADER)` | Sentiment analysis |
| `scikit-learn (LDA)` | Topic modelling |
| `fuzzywuzzy` | Fuzzy keyword matching |
| `pandas` | Data processing |
| `matplotlib / seaborn` | Visualisation (notebooks) |
| `wordcloud` | Word cloud generation (notebooks) |

---

## ğŸ‘¤ Author

**M. Siva Subramaniyen**

---

## ğŸ“ Notes

- The `Data/` folder is excluded from this repository via `.gitignore` due to file size
- Notebooks are standalone exploratory tools and are not part of the app pipeline
- Run `Genre_filter.py` whenever you get a fresh copy of the master dataset
